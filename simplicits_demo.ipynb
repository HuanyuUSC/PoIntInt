{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplicits Easy API Demo\n",
    "\n",
    "[Simplicits](https://research.nvidia.com/labs/toronto-ai/simplicits/) is a mesh-free, representation-agnostic way to simulate elastic deformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-30 01:41:33.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m16\u001b[0m - \u001b[1mImports loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import builtins\n",
    "import copy\n",
    "import threading\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import kaolin as kal\n",
    "import k3d\n",
    "from loguru import logger\n",
    "from tqdm.auto import tqdm\n",
    "from ipywidgets import Button, HBox, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "logger.info(\"Imports loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Helper functions\n@contextmanager\ndef training_progress_hook(total_steps):\n    \"\"\"Hook into Kaolin's training loop to show progress bar.\"\"\"\n    import kaolin.physics.simplicits.easy_api as easy_api\n    \n    original_range = getattr(easy_api, \"range\", builtins.range)\n    \n    def tqdm_range(*args):\n        rng = original_range(*args)\n        if hasattr(rng, \"__len__\") and len(rng) == total_steps:\n            return tqdm(rng, desc=\"Training\", total=total_steps, unit=\"step\", leave=False)\n        return rng\n    \n    easy_api.range = tqdm_range\n    try:\n        yield\n    finally:\n        if original_range is builtins.range:\n            if hasattr(easy_api, \"range\"):\n                delattr(easy_api, \"range\")\n        else:\n            easy_api.range = original_range\n\n\ndef load_and_sample_mesh(mesh_path, num_samples=200_000):\n    \"\"\"Load mesh, center it, and sample interior points.\"\"\"\n    mesh = kal.io.import_mesh(mesh_path, triangulate=True).cuda()\n    mesh.vertices = kal.ops.pointcloud.center_points(mesh.vertices.unsqueeze(0), normalize=True).squeeze(0)\n    orig_vertices = mesh.vertices.clone()\n    logger.info(f\"Loaded mesh: {len(mesh.vertices)} vertices, {len(mesh.faces)} faces\")\n    \n    # Sample interior points\n    min_corner = orig_vertices.min(dim=0).values\n    max_corner = orig_vertices.max(dim=0).values\n    uniform_pts = torch.rand(num_samples, 3, device='cuda') * (max_corner - min_corner) + min_corner\n    inside = kal.ops.mesh.check_sign(\n        mesh.vertices.unsqueeze(0), mesh.faces, uniform_pts.unsqueeze(0), hash_resolution=512\n    ).squeeze()\n    pts = uniform_pts[inside]\n    logger.info(f\"Sampled {len(pts)} interior points\")\n    \n    return mesh, orig_vertices, pts\n\n\ndef create_sim_object(pts, youngs=1e5, poisson=0.45, density=500.0, volume=0.5, handles=5, steps=10000):\n    \"\"\"Create and train a Simplicits simulation object with progress bar.\"\"\"\n    yms = torch.full((pts.shape[0],), youngs, device=\"cuda\")\n    prs = torch.full((pts.shape[0],), poisson, device=\"cuda\")\n    rhos = torch.full((pts.shape[0],), density, device=\"cuda\")\n    \n    logger.info(f\"Training Simplicits object: {steps} steps, {handles} handles\")\n    \n    # Use the training progress hook\n    with training_progress_hook(steps):\n        sim_obj = kal.physics.simplicits.SimplicitsObject.create_trained(\n            pts, yms, prs, rhos, volume,\n            num_handles=handles,\n            training_num_steps=steps,\n            training_lr_start=1e-3,\n            training_lr_end=1e-3,\n            training_le_coeff=1e-1,\n            training_lo_coeff=1e6,\n            training_log_every=max(1, steps // 10),\n            normalize_for_training=True\n        )\n    \n    logger.info(\"Training complete\")\n    return sim_obj\n\n\ndef setup_scene(sim_obj, gravity=(0, 9.8, 0), floor_height=-0.8, timestep=0.03):\n    \"\"\"Create scene and add physics.\"\"\"\n    scene = kal.physics.simplicits.SimplicitsScene()\n    scene.max_newton_steps = 5\n    scene.timestep = timestep\n    scene.direct_solve = True\n    \n    obj_idx = scene.add_object(sim_obj)\n    scene.set_scene_gravity(acc_gravity=torch.tensor(gravity))\n    scene.set_scene_floor(floor_height=floor_height, floor_axis=1, floor_penalty=1000)\n    \n    return scene, obj_idx\n\n\ndef create_floor_mesh(floor_height=-0.8, size=5.0):\n    \"\"\"Create a simple floor plane mesh.\"\"\"\n    floor_verts = torch.tensor([\n        [-size, floor_height, -size],\n        [size, floor_height, -size],\n        [size, floor_height, size],\n        [-size, floor_height, size]\n    ], device='cuda', dtype=torch.float32)\n    \n    floor_faces = torch.tensor([[0, 1, 2], [0, 2, 3]], device='cuda', dtype=torch.long)\n    \n    floor_mesh = kal.rep.SurfaceMesh(vertices=floor_verts, faces=floor_faces)\n    return floor_mesh\n\n\ndef create_renderer(mesh, floor_height=-0.8, resolution=512):\n    \"\"\"Setup rendering functions with floor.\"\"\"\n    camera = kal.render.easy_render.default_camera(resolution).cuda()\n    light_dir = kal.render.lighting.sg_direction_from_azimuth_elevation(1., 1.)\n    lighting = kal.render.lighting.SgLightingParameters(amplitude=3., sharpness=5., direction=light_dir).cuda()\n    \n    floor_mesh = create_floor_mesh(floor_height)\n    \n    def render(in_cam):\n        # Render object\n        obj_res = kal.render.easy_render.render_mesh(in_cam, mesh, lighting=lighting)\n        obj_img = obj_res[kal.render.easy_render.RenderPass.render]\n        obj_depth = obj_res[kal.render.easy_render.RenderPass.depth]\n        obj_mask = obj_res[kal.render.easy_render.RenderPass.face_idx] >= 0\n        \n        # Render floor\n        floor_res = kal.render.easy_render.render_mesh(in_cam, floor_mesh, lighting=lighting)\n        floor_img = floor_res[kal.render.easy_render.RenderPass.render] * 0.5 + 0.3  # Gray floor\n        floor_depth = floor_res[kal.render.easy_render.RenderPass.depth]\n        floor_mask = floor_res[kal.render.easy_render.RenderPass.face_idx] >= 0\n        \n        # Composite based on depth\n        combined_img = torch.ones_like(obj_img)\n        depth_mask = (obj_mask & floor_mask & (obj_depth < floor_depth)) | (obj_mask & ~floor_mask)\n        combined_img[depth_mask] = obj_img[depth_mask]\n        combined_img[floor_mask & ~depth_mask] = floor_img[floor_mask & ~depth_mask]\n        \n        img2 = torch.clamp(combined_img, 0, 1)[0]\n        return {\"img\": (img2 * 255.).to(torch.uint8)}\n    \n    def fast_render(in_cam, factor=8):\n        lowres_cam = copy.deepcopy(in_cam)\n        lowres_cam.width = in_cam.width // factor\n        lowres_cam.height = in_cam.height // factor\n        return render(lowres_cam)\n    \n    return camera, render, fast_render\n\n\nlogger.info(\"Helper functions defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Cannot convert Ka from obj mtl to PBR spec; use raw_materials=True to import raw values\n",
      "\u001b[32m2025-09-30 01:41:36.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_sample_mesh\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoaded mesh: 5002 vertices, 10000 faces\u001b[0m\n",
      "\u001b[32m2025-09-30 01:41:36.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_sample_mesh\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mSampled 44104 interior points\u001b[0m\n",
      "\u001b[32m2025-09-30 01:41:36.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mVisualizing sampled points...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bab38cc3fb45c3b4ecbc57199d7b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-30 01:41:36.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_sim_object\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mTraining Simplicits object: 10000 steps, 5 handles\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805dc15e3bdd4db69ec13973fd8361fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/10000 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-30 01:42:54.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_sim_object\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mTraining complete\u001b[0m\n",
      "d:\\code\\PoIntInt\\.venv\\Lib\\site-packages\\warp\\torch.py:262: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  if t.grad is not None:\n",
      "d:\\code\\PoIntInt\\.venv\\Lib\\site-packages\\kaolin\\physics\\utils\\warp_utilities.py:263: UserWarning: Sparse BSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\SparseCsrTensorImpl.cpp:55.)\n",
      "  torch_weights = ctor(\n",
      "\u001b[32m2025-09-30 01:42:59.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mSetup complete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Main workflow\n",
    "mesh_path = \"assets/fox.obj\"\n",
    "\n",
    "# Load and sample\n",
    "mesh, orig_vertices, pts = load_and_sample_mesh(mesh_path)\n",
    "\n",
    "# Visualize sampled points\n",
    "logger.info(\"Visualizing sampled points...\")\n",
    "plot = k3d.plot()\n",
    "plot += k3d.points(pts.cpu().numpy(), point_size=0.01)\n",
    "plot.display()\n",
    "\n",
    "# Train simulation object\n",
    "sim_obj = create_sim_object(pts)\n",
    "\n",
    "# Setup scene\n",
    "scene, obj_idx = setup_scene(sim_obj)\n",
    "\n",
    "logger.info(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\PoIntInt\\.venv\\Lib\\site-packages\\kaolin\\render\\easy_render\\mesh.py:282: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:67.)\n",
      "  im_bitangents = torch.nn.functional.normalize(torch.cross(im_tangents, im_base_normals), dim=-1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0508dd68c943f793eca3ca2065371d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Canvas(height=512, width=512), VBox(children=(Button(description='Run Sim', style=ButtonStyle()â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536bb7ac6a4644b79702b2f9e8c0fab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "mesh.vertices = orig_vertices\n",
    "\n",
    "global sim_thread_open, sim_thread\n",
    "sim_thread_open = False\n",
    "sim_thread = None\n",
    "\n",
    "def reset_simulation(visualizer):\n",
    "    with visualizer.out:\n",
    "        scene.reset_scene()\n",
    "    mesh.vertices = scene.get_object_deformed_pts(obj_idx, orig_vertices)\n",
    "    visualizer.render_update()\n",
    "\n",
    "def run_sim():\n",
    "    for _ in range(100):\n",
    "        with visualizer.out:\n",
    "            scene.run_sim_step()\n",
    "            print(\".\", end=\"\")\n",
    "        mesh.vertices = scene.get_object_deformed_pts(obj_idx, orig_vertices)\n",
    "        visualizer.render_update()\n",
    "\n",
    "def start_simulation(b):\n",
    "    global sim_thread_open, sim_thread\n",
    "    with visualizer.out:\n",
    "        if sim_thread_open:\n",
    "            sim_thread.join()\n",
    "            sim_thread_open = False\n",
    "        sim_thread_open = True\n",
    "        sim_thread = threading.Thread(target=run_sim, daemon=True)\n",
    "        sim_thread.start()\n",
    "\n",
    "camera, render, fast_render = create_renderer(mesh)\n",
    "visualizer = kal.visualize.IpyTurntableVisualizer(\n",
    "    512, 512, copy.deepcopy(camera), render, fast_render=fast_render,\n",
    "    max_fps=24, world_up_axis=1\n",
    ")\n",
    "\n",
    "buttons = [Button(description=x) for x in ['Run Sim', 'Reset']]\n",
    "buttons[0].on_click(lambda e: start_simulation(e))\n",
    "buttons[1].on_click(lambda e: reset_simulation(visualizer))\n",
    "\n",
    "reset_simulation(visualizer)\n",
    "display(HBox([visualizer.canvas, VBox(buttons)]), visualizer.out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}